<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Patterns on Arc</title>
    <link>https://aglenergy.github.io/arc/patterns/</link>
    <description>Recent content in Patterns on Arc</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://aglenergy.github.io/arc/patterns/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Patterns</title>
      <link>https://aglenergy.github.io/arc/patterns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://aglenergy.github.io/arc/patterns/</guid>
      <description>Database Inconsistency When writing data to targets like databases using the JDBCLoad raises a risk of &amp;lsquo;stale reads&amp;rsquo; where a client is reading a dataset which is either old or one which is in the process of being updated and so is internally inconsistent. A pattern for preventing this is to:
 create a new table each run using a JDBCLoad stage with a dynamic destination table specified as the ${JOB_RUN_DATE} environment variable the JDBCLoad will only complete successfully once the record count of source and target data have been confirmed to match execute a JDBCExecute stage to perform a change to a view on the database to point to the new version of the table in a transaction-safe manner if the job fails during any of these stages then the users will be unaware and will continue to consume the customers view which has the latest successful data  { &amp;quot;type&amp;quot;: &amp;quot;JDBCLoad&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;load active customers to web server database&amp;quot;, &amp;quot;environments&amp;quot;: [&amp;quot;production&amp;quot;, &amp;quot;test&amp;quot;], &amp;quot;inputView&amp;quot;: &amp;quot;ative_customers&amp;quot;, &amp;quot;jdbcURL&amp;quot;: &amp;quot;jdbc:mysql://localhost/mydb&amp;quot;, &amp;quot;tableName&amp;quot;: &amp;quot;customers_&amp;quot;${JOB_RUN_DATE}, &amp;quot;numPartitions&amp;quot;: 10, &amp;quot;isolationLevel&amp;quot;: &amp;quot;READ_COMMITTED&amp;quot;, &amp;quot;batchsize&amp;quot;: 10000, &amp;quot;params&amp;quot;: { &amp;quot;user&amp;quot;: &amp;quot;mydbuser&amp;quot;, &amp;quot;password&amp;quot;: &amp;quot;mydbpassword&amp;quot;, } }, { &amp;quot;type&amp;quot;: &amp;quot;JDBCExecute&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;update the current view to point to the latest version of the table&amp;quot;, &amp;quot;environments&amp;quot;: [&amp;quot;production&amp;quot;, &amp;quot;test&amp;quot;], &amp;quot;inputURI&amp;quot;: &amp;quot;hdfs://datalake/sql/update_customer_view.</description>
    </item>
    
  </channel>
</rss>